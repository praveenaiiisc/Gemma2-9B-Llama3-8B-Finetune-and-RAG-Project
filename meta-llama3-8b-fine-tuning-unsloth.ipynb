{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-2hzelkpv/unsloth_a3bea51428084509bf917b450a767c4f\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-2hzelkpv/unsloth_a3bea51428084509bf917b450a767c4f\n","  Resolved https://github.com/unslothai/unsloth.git to commit 4be284bd79d2c4ffab378b93d7282b54f96647e9\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n","Collecting transformers>=4.42.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n","Collecting datasets>=2.16.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n","Collecting sentencepiece>=0.2.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Collecting tqdm (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n","Requirement already satisfied: psutil in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.0)\n","Requirement already satisfied: wheel>=0.42.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n","Collecting numpy (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m392.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n","Requirement already satisfied: filelock in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.15.4)\n","Collecting pyarrow>=15.0.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n","Collecting pyarrow-hotfix (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting pandas (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n","Collecting requests>=2.32.2 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Collecting xxhash (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n","Collecting aiohttp (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n","Collecting huggingface-hub>=0.21.2 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: packaging in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n","Collecting pyyaml>=5.1 (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n","Collecting numpy (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m357.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting regex!=2019.12.17 (from transformers>=4.42.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m224.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.4.1 (from transformers>=4.42.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Collecting tokenizers<0.20,>=0.19 (from transformers>=4.42.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting docstring-parser>=0.16 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n","Collecting rich>=11.1.0 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n","Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n","Collecting attrs>=17.3.0 (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n","Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n","Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n","Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n","Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n","Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0)\n","Collecting pytz>=2020.1 (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: six>=1.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Using cached datasets-2.20.0-py3-none-any.whl (547 kB)\n","Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n","Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hUsing cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n","Using cached transformers-4.42.3-py3-none-any.whl (9.3 MB)\n","Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hUsing cached tyro-0.8.5-py3-none-any.whl (103 kB)\n","Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n","Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n","Using cached fsspec-2024.5.0-py3-none-any.whl (316 kB)\n","Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hUsing cached huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n","Downloading pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n","Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n","Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hUsing cached shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m820.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hUsing cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hUsing cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n","Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n","Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m84.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m540.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hUsing cached idna-3.7-py3-none-any.whl (66 kB)\n","Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n","Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hUsing cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n","Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n","Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hUsing cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Building wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.7-py3-none-any.whl size=126780 sha256=bcab145d435848567b21180908edfc232c92f0a5a691d625da652333cf2eacee\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-xswn9jo0/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n","Successfully built unsloth\n","Installing collected packages: sentencepiece, pytz, xxhash, urllib3, unsloth, tzdata, tqdm, shtab, safetensors, regex, pyyaml, pyarrow-hotfix, protobuf, numpy, multidict, mdurl, idna, fsspec, frozenlist, docstring-parser, dill, charset-normalizer, certifi, attrs, yarl, requests, pyarrow, pandas, multiprocess, markdown-it-py, aiosignal, rich, huggingface-hub, aiohttp, tyro, tokenizers, transformers, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.6.1\n","    Uninstalling fsspec-2024.6.1:\n","      Successfully uninstalled fsspec-2024.6.1\n","Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 certifi-2024.7.4 charset-normalizer-3.3.2 datasets-2.20.0 dill-0.3.8 docstring-parser-0.16 frozenlist-1.4.1 fsspec-2024.5.0 huggingface-hub-0.23.4 idna-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.0.5 multiprocess-0.70.16 numpy-1.26.4 pandas-2.2.2 protobuf-3.20.3 pyarrow-16.1.0 pyarrow-hotfix-0.6 pytz-2024.1 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.3 rich-13.7.1 safetensors-0.4.3 sentencepiece-0.2.0 shtab-1.7.1 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.42.3 tyro-0.8.5 tzdata-2024.1 unsloth-2024.7 urllib3-2.2.2 xxhash-3.4.1 yarl-1.9.4\n","Requirement already satisfied: packaging in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (24.1)\n","Collecting ninja\n","  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n","Collecting einops\n","  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Collecting flash-attn\n","  Using cached flash_attn-2.5.9.post1.tar.gz (2.6 MB)\n","  Preparing metadata (setup.py) ... \u001b[?25lerror\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m \u001b[31m[22 lines of output]\u001b[0m\n","  \u001b[31m   \u001b[0m fatal: not a git repository (or any of the parent directories): .git\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m torch.__version__  = 2.3.1+cu121\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m /tmp/pip-install-0ma6qh5o/flash-attn_e4b383c149a34815ab87e26efa54855a/setup.py:78: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n","  \u001b[31m   \u001b[0m   warnings.warn(\n","  \u001b[31m   \u001b[0m Traceback (most recent call last):\n","  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n","  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n","  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-0ma6qh5o/flash-attn_e4b383c149a34815ab87e26efa54855a/setup.py\", line 134, in <module>\n","  \u001b[31m   \u001b[0m     CUDAExtension(\n","  \u001b[31m   \u001b[0m   File \"/home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1077, in CUDAExtension\n","  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n","  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^\n","  \u001b[31m   \u001b[0m   File \"/home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1204, in library_paths\n","  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n","  \u001b[31m   \u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^\n","  \u001b[31m   \u001b[0m   File \"/home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 2419, in _join_cuda_home\n","  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n","  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n","  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Requirement already satisfied: triton in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (2.3.1)\n","Requirement already satisfied: transformers in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (4.42.3)\n","Requirement already satisfied: filelock in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from triton) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: datasets in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (2.20.0)\n","Requirement already satisfied: filelock in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (4.66.4)\n","Requirement already satisfied: xxhash in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n","Requirement already satisfied: aiohttp in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (0.23.4)\n","Requirement already satisfied: packaging in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n","Requirement already satisfied: pytz>=2020.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Collecting xformers\n","  Downloading xformers-0.0.27.dev845-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from xformers) (1.26.4)\n","Collecting torch==2.3.0 (from xformers)\n","  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: filelock in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (4.12.2)\n","Requirement already satisfied: sympy in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (1.12.1)\n","Requirement already satisfied: networkx in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (3.3)\n","Requirement already satisfied: jinja2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (3.1.4)\n","Requirement already satisfied: fsspec in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (2024.5.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch==2.3.0->xformers) (12.1.105)\n","Collecting triton==2.3.0 (from torch==2.3.0->xformers)\n","  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->xformers) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from jinja2->torch==2.3.0->xformers) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from sympy->torch==2.3.0->xformers) (1.3.0)\n","Downloading xformers-0.0.27.dev845-cp311-cp311-manylinux2014_x86_64.whl (164.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, torch, xformers\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.3.1\n","    Uninstalling triton-2.3.1:\n","      Successfully uninstalled triton-2.3.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.3.1\n","    Uninstalling torch-2.3.1:\n","      Successfully uninstalled torch-2.3.1\n","Successfully installed torch-2.3.0 triton-2.3.0 xformers-0.0.27.dev845\n"]}],"source":["import torch\n","major_version, minor_version = torch.cuda.get_device_capability()\n","! pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","if major_version >= 8:\n","    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n","    ! pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n","else:\n","    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n","    ! pip install --no-deps xformers trl peft accelerate bitsandbytes\n","pass\n","! pip install triton transformers\n","! pip install -U datasets\n","! pip install --pre -U xformers ##### this take some time"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (4.42.3)\n","Requirement already satisfied: accelerate in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (0.32.1)\n","Requirement already satisfied: bitsandbytes in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (0.43.1)\n","Requirement already satisfied: filelock in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: psutil in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from accelerate) (5.9.0)\n","Requirement already satisfied: torch>=1.10.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from accelerate) (2.3.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: sympy in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.82)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Collecting peft\n","  Using cached peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (24.1)\n","Requirement already satisfied: psutil in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (5.9.0)\n","Requirement already satisfied: pyyaml in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (2.3.0)\n","Requirement already satisfied: transformers in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (4.42.3)\n","Requirement already satisfied: tqdm in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (4.66.4)\n","Requirement already satisfied: accelerate>=0.21.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (0.32.1)\n","Requirement already satisfied: safetensors in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (0.4.3)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from peft) (0.23.4)\n","Requirement already satisfied: filelock in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n","Requirement already satisfied: requests in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n","Requirement already satisfied: sympy in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.12.1)\n","Requirement already satisfied: networkx in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3)\n","Requirement already satisfied: jinja2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from torch>=1.13.0->peft) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.5.82)\n","Requirement already satisfied: regex!=2019.12.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers->peft) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from transformers->peft) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/praveent/.conda/envs/llama_proj/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Using cached peft-0.11.1-py3-none-any.whl (251 kB)\n","Installing collected packages: peft\n","Successfully installed peft-0.11.1\n"]}],"source":["! pip install transformers accelerate bitsandbytes\n","! pip install peft"]},{"cell_type":"markdown","metadata":{},"source":["Note Restart the Kernal after package installation"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:48:17.855133Z","iopub.status.busy":"2024-04-19T15:48:17.854873Z","iopub.status.idle":"2024-04-19T15:48:23.926428Z","shell.execute_reply":"2024-04-19T15:48:23.925520Z","shell.execute_reply.started":"2024-04-19T15:48:17.855109Z"},"trusted":true},"outputs":[{"ename":"OSError","evalue":"could not find class definition","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from transformers import BitsAndBytesConfig, bitsandbytes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraLayer\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display_markdown\n","File \u001b[0;32m~/.conda/envs/llama_proj/lib/python3.11/site-packages/unsloth/__init__.py:149\u001b[0m\n\u001b[1;32m    139\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: CUDA is not linked properly.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry running `python -m bitsandbytes` then `python -m xformers.info`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth will still run for now, but maybe it might crash - let\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms hope it works!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         )\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msave\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_templates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m~/.conda/envs/llama_proj/lib/python3.11/site-packages/unsloth/models/__init__.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023-present Daniel Han-Chen & the Unsloth team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m  \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama\u001b[39;00m   \u001b[38;5;28;01mimport\u001b[39;00m FastLlamaModel\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmistral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastMistralModel\n","File \u001b[0;32m~/.conda/envs/llama_proj/lib/python3.11/site-packages/unsloth/models/loader.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023-present Daniel Han-Chen & the Unsloth team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLlamaModel, logger\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmistral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastMistralModel\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqwen2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastQwen2Model\n","File \u001b[0;32m~/.conda/envs/llama_proj/lib/python3.11/site-packages/unsloth/models/llama.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Tuple, List, Union\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scaled_dot_product_attention\n","File \u001b[0;32m~/.conda/envs/llama_proj/lib/python3.11/site-packages/unsloth/models/_utils.py:77\u001b[0m\n\u001b[1;32m     74\u001b[0m config_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m exec(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_filepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m---> 77\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsource\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_filename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_scaling\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     79\u001b[0m config \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m*kwargs)[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0,}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m,[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0,}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m0,}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_scaling=None,\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     config,\n\u001b[1;32m     85\u001b[0m )\n","File \u001b[0;32m~/.conda/envs/llama_proj/lib/python3.11/inspect.py:1270\u001b[0m, in \u001b[0;36mgetsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetsource\u001b[39m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the text of the source code for an object.\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m \n\u001b[1;32m   1267\u001b[0m \u001b[38;5;124;03m    The argument may be a module, class, method, function, traceback, frame,\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;124;03m    or code object.  The source code is returned as a single string.  An\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;124;03m    OSError is raised if the source code cannot be retrieved.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m     lines, lnum \u001b[38;5;241m=\u001b[39m \u001b[43mgetsourcelines\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lines)\n","File \u001b[0;32m~/.conda/envs/llama_proj/lib/python3.11/inspect.py:1252\u001b[0m, in \u001b[0;36mgetsourcelines\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of source lines and starting line number for an object.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \n\u001b[1;32m   1246\u001b[0m \u001b[38;5;124;03mThe argument may be a module, class, method, function, traceback, frame,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;124;03moriginal source file the first line of code was found.  An OSError is\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;124;03mraised if the source code cannot be retrieved.\"\"\"\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m unwrap(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m lines, lnum \u001b[38;5;241m=\u001b[39m \u001b[43mfindsource\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m istraceback(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mtb_frame\n","File \u001b[0;32m~/.conda/envs/llama_proj/lib/python3.11/inspect.py:1097\u001b[0m, in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lines, line_number\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1097\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not find class definition\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismethod(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m\n","\u001b[0;31mOSError\u001b[0m: could not find class definition"]}],"source":["# from transformers import BitsAndBytesConfig, bitsandbytes\n","from peft.tuners.lora.layer import LoraLayer\n","from unsloth import FastLanguageModel\n","import torch\n","from IPython.display import display_markdown\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/llama-3-8b-bnb-4bit\",  \n","]  #### loadin llama 3 model in 4 bit to fine tune"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:48:23.928721Z","iopub.status.busy":"2024-04-19T15:48:23.928329Z","iopub.status.idle":"2024-04-19T15:49:25.364770Z","shell.execute_reply":"2024-04-19T15:49:25.363950Z","shell.execute_reply.started":"2024-04-19T15:48:23.928694Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c03d46d3e2dc429db11516a2a441a49b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["==((====))==  Unsloth: Fast Llama patching release 2024.4\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.2.2+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. Xformers = 0.0.26.dev778. FA = False.\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58f6e6d895704a2995edf608efd74b5f","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db945957c9544656bac1f416d221d665","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b1901e8c5ee45938b902347468ed163","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"482061b34ea14a26852dc2b866593df1","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4e111ede2c44a93b172ea36f8a01328","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","2024-04-19 15:49:14.219228: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-19 15:49:14.219343: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-19 15:49:14.372882: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,       # Qlore config\n","    token = \"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\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["ref_config https://github.com/pytorch/torchtune/blob/main/recipes/configs/llama3/8B_qlora_single_device.yaml"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:49:25.366485Z","iopub.status.busy":"2024-04-19T15:49:25.365896Z","iopub.status.idle":"2024-04-19T15:49:26.216053Z","shell.execute_reply":"2024-04-19T15:49:26.215315Z","shell.execute_reply.started":"2024-04-19T15:49:25.366458Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Unsloth 2024.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 8, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:49:26.219027Z","iopub.status.busy":"2024-04-19T15:49:26.218365Z","iopub.status.idle":"2024-04-19T15:49:29.842078Z","shell.execute_reply":"2024-04-19T15:49:29.841258Z","shell.execute_reply.started":"2024-04-19T15:49:26.218991Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b6155a70c38452983a9833a3dd6c61b","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/2.50k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e42af5f383cc4421a0afed0d508c9b2b","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/57.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37cefb05e5e94fb8ba71a460f2c57976","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/142622 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["#### dataset import \n","dataset_name = \"VMware/open-instruct\"\n","from datasets import load_dataset\n","dataset = load_dataset(dataset_name, split=\"train\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:49:29.843501Z","iopub.status.busy":"2024-04-19T15:49:29.843164Z","iopub.status.idle":"2024-04-19T15:49:29.848691Z","shell.execute_reply":"2024-04-19T15:49:29.847682Z","shell.execute_reply.started":"2024-04-19T15:49:29.843455Z"},"trusted":true},"outputs":[],"source":["# Must add EOS_TOKEN at response last line\n","EOS_TOKEN = tokenizer.eos_token \n","def mapping_response(sample):\n","    sample['text'] = sample['alpaca_prompt']+\"\\n\"+sample['response']+EOS_TOKEN\n","    return sample"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:49:29.850796Z","iopub.status.busy":"2024-04-19T15:49:29.849932Z","iopub.status.idle":"2024-04-19T15:49:30.012477Z","shell.execute_reply":"2024-04-19T15:49:30.011472Z","shell.execute_reply.started":"2024-04-19T15:49:29.850761Z"},"trusted":true},"outputs":[],"source":["### selecting only 2000 samples for testing\n","dataset = dataset.select(range(2000))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:49:30.014089Z","iopub.status.busy":"2024-04-19T15:49:30.013787Z","iopub.status.idle":"2024-04-19T15:49:30.304663Z","shell.execute_reply":"2024-04-19T15:49:30.303724Z","shell.execute_reply.started":"2024-04-19T15:49:30.014065Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33b7bec750e14ed299762e72457aa789","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = dataset.map(mapping_response)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:49:30.306120Z","iopub.status.busy":"2024-04-19T15:49:30.305834Z","iopub.status.idle":"2024-04-19T15:49:30.311604Z","shell.execute_reply":"2024-04-19T15:49:30.310619Z","shell.execute_reply.started":"2024-04-19T15:49:30.306095Z"},"trusted":true},"outputs":[],"source":["def prompt_inference(prmpt):\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","    inputs = tokenizer(\n","    [\n","        prmpt\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    outputs = model.generate(**inputs, max_new_tokens = 512, use_cache = True)\n","    return tokenizer.batch_decode(outputs)[0].split(\"### Response:\")[-1]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:49:30.314742Z","iopub.status.busy":"2024-04-19T15:49:30.314468Z","iopub.status.idle":"2024-04-19T15:49:30.333025Z","shell.execute_reply":"2024-04-19T15:49:30.332094Z","shell.execute_reply.started":"2024-04-19T15:49:30.314712Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Generate the lyrics to a song that begins like this \"Hey hey let's go...\"\n","\n","### Response:\n"]}],"source":["prompt = dataset['alpaca_prompt'][90]\n","print(prompt)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:49:30.334282Z","iopub.status.busy":"2024-04-19T15:49:30.333994Z","iopub.status.idle":"2024-04-19T15:50:05.417591Z","shell.execute_reply":"2024-04-19T15:50:05.416601Z","shell.execute_reply.started":"2024-04-19T15:49:30.334259Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["result\n"]},{"data":{"text/markdown":[" \n","Hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey hey let's go, hey"]},"metadata":{},"output_type":"display_data"}],"source":["print(\"result\")\n","display_markdown(prompt_inference(prmpt=prompt),raw=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### the above result is not clear ,without fine tuning"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:50:05.419725Z","iopub.status.busy":"2024-04-19T15:50:05.419034Z","iopub.status.idle":"2024-04-19T15:50:08.474165Z","shell.execute_reply":"2024-04-19T15:50:08.473312Z","shell.execute_reply.started":"2024-04-19T15:50:05.419688Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0389487b8bd543c785c5b36624c7b958","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=2):   0%|          | 0/2000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\", ### taking text column from the dataset\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 1,\n","        gradient_accumulation_steps = 2,\n","        warmup_steps = 500,\n","        max_steps = 800,\n","        learning_rate = 2e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        logging_steps = 100,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",num_train_epochs =1\n","    ),\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T15:53:11.099147Z","iopub.status.busy":"2024-04-19T15:53:11.098740Z","iopub.status.idle":"2024-04-19T16:21:11.419893Z","shell.execute_reply":"2024-04-19T16:21:11.419032Z","shell.execute_reply.started":"2024-04-19T15:53:11.099114Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 2,000 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 2\n","\\        /    Total batch size = 2 | Total steps = 800\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f4f74e4792814be3ad92da8d51df2ffa","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112882922225254, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240419_155342-66nqx8jp</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/hemanth2112/huggingface/runs/66nqx8jp' target=\"_blank\">sage-energy-80</a></strong> to <a href='https://wandb.ai/hemanth2112/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/hemanth2112/huggingface' target=\"_blank\">https://wandb.ai/hemanth2112/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/hemanth2112/huggingface/runs/66nqx8jp' target=\"_blank\">https://wandb.ai/hemanth2112/huggingface/runs/66nqx8jp</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [800/800 27:04, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.475300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.231300</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.176200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.221700</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.197700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.234700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>1.197600</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>1.211500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=800, training_loss=1.2432494068145752, metrics={'train_runtime': 1679.8268, 'train_samples_per_second': 0.952, 'train_steps_per_second': 0.476, 'total_flos': 2.051551084444877e+16, 'train_loss': 1.2432494068145752, 'epoch': 0.8})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["prompt = dataset['alpaca_prompt'][92]\n","print(prompt)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-19T16:21:18.928002Z","iopub.status.busy":"2024-04-19T16:21:18.927271Z","iopub.status.idle":"2024-04-19T16:21:26.213153Z","shell.execute_reply":"2024-04-19T16:21:26.211922Z","shell.execute_reply.started":"2024-04-19T16:21:18.927961Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["result\n"]},{"data":{"text/markdown":[" \n","Hey hey let's go\n","We're gonna have a good time\n","We're gonna make some noise\n","We're gonna have a blast\n","Hey hey let's go\n","We're gonna sing and dance\n","We're gonna make some memories\n","We're gonna have a blast\n","Hey hey let's go\n","We're gonna have a party\n","We're gonna make some friends\n","We're gonna have a blast\n","Hey hey let's go\n","We're gonna have a good time\n","We're gonna make some noise\n","We're gonna have a blast<|end_of_text|>"]},"metadata":{},"output_type":"display_data"}],"source":["print(\"result\")\n","display_markdown(prompt_inference(prmpt=prompt),raw=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}
