{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1c691f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "# del variables\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ffc0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda2 = torch.device('cuda:2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebf0401",
   "metadata": {},
   "source": [
    "### Step1: Requirements Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b43de97-6a76-463e-a10d-2071fd563f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (3.20.3)\n",
      "Requirement already satisfied: scikit-learn in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: scipy in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wandb in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (0.17.4)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (2.7.1)\n",
      "Requirement already satisfied: setproctitle in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.7.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/praveent/.cache/huggingface/token\n",
      "Login successful\n",
      "Requirement already satisfied: transformers[sentencepiece] in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (4.40.0)\n",
      "Requirement already satisfied: filelock in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (4.66.4)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers[sentencepiece]) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests->transformers[sentencepiece]) (2024.7.4)\n",
      "Requirement already satisfied: sentencepiece in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (0.2.0)\n",
      "/bin/bash: apt-get: command not found\n",
      "Requirement already satisfied: tensorboardX in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from tensorboardX) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from tensorboardX) (24.1)\n",
      "Requirement already satisfied: protobuf>=3.20 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from tensorboardX) (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install protobuf scikit-learn scipy\n",
    "! export CUDA_HOME=cuda-12.2\n",
    "! pip install wandb\n",
    "! pip install -q accelerate  bitsandbytes  trl==0.4.7\n",
    "! huggingface-cli login --token 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\n",
    "! pip install  transformers[sentencepiece]\n",
    "! pip install sentencepiece\n",
    "! apt-get install git-lfs\n",
    "! pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bd94ce-13fa-4115-8f04-11ad3bb3aba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==0.29.3 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (0.29.3)\n",
      "Requirement already satisfied: peft==0.10.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (0.10.0)\n",
      "Requirement already satisfied: bitsandbytes==0.41.3 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (0.41.3)\n",
      "Requirement already satisfied: transformers==4.40.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (4.40.0)\n",
      "Collecting trl==0.8.5\n",
      "  Using cached trl-0.8.5-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from accelerate==0.29.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from accelerate==0.29.3) (24.1)\n",
      "Requirement already satisfied: psutil in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from accelerate==0.29.3) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from accelerate==0.29.3) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from accelerate==0.29.3) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from accelerate==0.29.3) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from accelerate==0.29.3) (0.4.3)\n",
      "Requirement already satisfied: tqdm in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from peft==0.10.0) (4.66.4)\n",
      "Requirement already satisfied: filelock in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers==4.40.0) (3.15.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers==4.40.0) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers==4.40.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from transformers==4.40.0) (0.19.1)\n",
      "Requirement already satisfied: datasets in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from trl==0.8.5) (2.20.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from trl==0.8.5) (0.8.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.29.3) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from huggingface-hub->accelerate==0.29.3) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.5.82)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.8.5) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.8.5) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.8.5) (1.7.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from datasets->trl==0.8.5) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from datasets->trl==0.8.5) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from datasets->trl==0.8.5) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from datasets->trl==0.8.5) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from datasets->trl==0.8.5) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from datasets->trl==0.8.5) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from datasets->trl==0.8.5) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests->transformers==4.40.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests->transformers==4.40.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests->transformers==4.40.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from requests->transformers==4.40.0) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.8.5) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.8.5) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.8.5) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.8.5) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from aiohttp->datasets->trl==0.8.5) (1.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.5) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.5) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from pandas->datasets->trl==0.8.5) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from pandas->datasets->trl==0.8.5) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from pandas->datasets->trl==0.8.5) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.5) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.8.5) (1.16.0)\n",
      "Using cached trl-0.8.5-py3-none-any.whl (245 kB)\n",
      "Installing collected packages: trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.4.7\n",
      "    Uninstalling trl-0.4.7:\n",
      "      Successfully uninstalled trl-0.4.7\n",
      "Successfully installed trl-0.8.5\n"
     ]
    }
   ],
   "source": [
    "! pip install -U accelerate==0.29.3 peft==0.10.0 bitsandbytes==0.41.3 transformers==4.40.0 trl==0.8.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b22b7d-9144-47f4-90f5-f2190e9b9fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: NVIDIA GeForce RTX 3090\n",
      "GPU model: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU model:\", torch.cuda.get_device_name(2))\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4526cde9-8b9b-4917-bb50-d1dd284de4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel               # import Lora config\n",
    "from trl import SFTTrainer                           # import trainer for supervised finetunning\n",
    "hf_token = \"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\"   # get authontication permisson from haggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6943fe",
   "metadata": {},
   "source": [
    "### Step2: Import Model and toknizer and its requirements from HaggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9985edf-667a-4326-81c1-f5526bf34375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that you want to train from the Hugging Face hub\n",
    "model_name = \"NousResearch/Meta-Llama-3-8B\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "dataset_name = \"Hemanth-thunder/tamil-open-instruct-v1\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"llama-3-8b-tamil-open-instruct-v1\"\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 1\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 16\n",
    "\n",
    "# Batch size per GPU for evaluation\n",
    "per_device_eval_batch_size = 16\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 2\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 2\n",
    "device_map = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3b93ec1-47a0-45e9-926b-0bcae1c0fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (you can process it here)\n",
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adcefe75-8f08-4bad-8a9d-14a2a8a26507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output', 'input', 'text'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset = dataset.shuffle().select(range(10000))\n",
    "sample_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf647af-06a1-4934-a27e-df9b3547389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "சரியான பதிலுடன் வேலையை வெற்றிகரமாக முடிக்க. தேவையான தகவலை உள்ளிடவும்.\n",
      "\n",
      "### Instruction:\n",
      "ஒரு உணவின் பெயரைக் கொண்டு, அது எதனால் ஆனது என்று சொல்லுங்கள். பீஸ்ஸா\n",
      "\n",
      "### Response:\n",
      "மாவை, சாஸ், சீஸ், மேல்புறம்\n"
     ]
    }
   ],
   "source": [
    "print(sample_dataset['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bfbb931-68dc-42fc-bcfc-e2e0fd9277fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    " \n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map,\n",
    "    token=hf_token\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afafb0bd-29bc-4800-ae50-1bf7bcbeff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1da6f461-1cec-4500-9022-11ed50875f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must add EOS_TOKEN at response last line\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token \n",
    "def prompt_eos(sample):\n",
    "    sample['text'] = sample['text']+EOS_TOKEN\n",
    "    return sample\n",
    "dataset = dataset.map(prompt_eos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6669ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "சரியான பதிலுடன் வேலையை வெற்றிகரமாக முடிக்க, வழங்கப்பட்ட வழிகாட்டுதல்களைப் பின்பற்றி, தேவையான தகவலை உள்ளிடவும்.\n",
      "\n",
      "### Instruction:\n",
      "இலக்கணம், வாக்கிய அமைப்பு மற்றும் தெளிவு ஆகியவற்றை மேம்படுத்த பின்வரும் பத்தியை மறுபரிசீலனை செய்யவும். \n",
      "\n",
      "### Input:\n",
      "நகரங்களில் வாழ்க்கை இன்று மிகவும் அழுத்தமாக இருக்கலாம். போக்குவரத்து நெரிசல் மற்றும் நிரம்பிய பொது போக்குவரத்து மக்களை வாக்குவாதத்திற்கும் சண்டைக்கும் வழிவகுக்கும். மன மற்றும் உடல் ஆரோக்கியத்தை பாதிக்கும் மற்றொரு பிரச்சனை மாசு. சமாளிப்பதற்கான வழிகளைக் கண்டுபிடிப்பது முக்கியம்.\n",
      "\n",
      "### Response:\n",
      "நகரங்களில் வாழ்க்கை இந்த நாட்களில் மிகவும் அழுத்தமாக உள்ளது. போக்குவரத்து நெரிசல் மற்றும் நெரிசலான பொது போக்குவரத்து வாக்குவாதங்கள் மற்றும் மோதல்களுக்கு வழிவகுக்கும். மாசுபாடு என்பது மன மற்றும் உடல் ஆரோக்கியத்தை எதிர்மறையாக பாதிக்கும் மற்றொரு பிரச்சினை. சமாளிப்பதற்கான வழிகளைக் கண்டுபிடிப்பது முக்கியம்.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5352bdf5",
   "metadata": {},
   "source": [
    "### Step3: Set Supervised FineTunning Parameter and Strat Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c197b380-2c70-4c6a-a4a9-97fbe62d7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6d21207-8de4-4b98-bf1b-66f2fa43456d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveent/.conda/envs/new_proj/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 493813/493813 [02:35<00:00, 3173.00 examples/s]\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(                  # fully supervised finting on give dataset\n",
    "    model=model,\n",
    "    train_dataset=dataset,             # finetuning on this dataset\n",
    "    peft_config=peft_config,           # load Lora Config for finetunning\n",
    "    dataset_text_field=\"text\",\n",
    "    # max_seq_length=max_seq_length,     # set maximum sequence length\n",
    "    tokenizer=tokenizer,               # pass toknizer\n",
    "    args=training_arguments,           # Pass all traing arguments those i require for fully supervised finetunning my model \n",
    "    packing=packing,\n",
    "    # class=transformers.utils.quantization_config.BitsAndBytesConfig\n",
    ")#.to(cuda2)\n",
    "\n",
    "\n",
    "# If you want to use the PeftModel, you need to pass a PeftConfig object to the SFTTrainer. \n",
    "# and you passed a <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12168034-3c16-40f9-9144-29cb0890ab50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train().to(\"cuda:2\")    # Model has trained on my traning dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8afa5",
   "metadata": {},
   "source": [
    "### Step4: Generate Response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d1fa166-3fd6-4f8e-8da2-23c210c5e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "    encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "    model_inputs = encoded_input.to('cuda:2')\n",
    "    \n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=512, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "    \n",
    "    return decoded_output[0].replace(prompt, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "098c5a4c-5de1-4062-8ec2-dad8e5784613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' இ-காமர்ஸ் இணையதளத்தை உருவாக்குவதற்கான செலவை மதிப்பிடவும்.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset['instruction'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d233579-fefe-4234-ba46-a5c165bdc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_wo_input=\"\"\"சரியான பதிலுடன் வேலையை வெற்றிகரமாக முடிக்க, தேவையான தகவலை உள்ளிடவும்.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "# with Input\n",
    "prompt_template_input=\"\"\"சரியான பதிலுடன் வேலையை வெற்றிகரமாக முடிக்க, வழங்கப்பட்ட வழிகாட்டுதல்களைப் பின்பற்றி, தேவையான தகவலை உள்ளிடவும்.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb03cea4-c1a2-4842-8f74-f70749687936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_prompt(sample):\n",
    "#     if 'nan' not in sample['input']:\n",
    "#       prompt = prompt_template_input.format(sample['instruction'][-1].strip(),sample['input'])\n",
    "#     else:\n",
    "#      prompt = prompt_template_wo_input.format(sample['instruction'][-1].strip())\n",
    "#     return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aec4efd4-e44f-47b9-8ba7-6d3610b6bcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nகாசோலிக்கு எவ்வளவு பணம் சேமிக்க வேண்டும் என்பது எங்களுக்கு முக்கியமானது, ஏனென்றால் பொருளாதார நிகழ்வுகளால் அடிப்படையான சேமிப்பு எங்கள் வாங்க முடிவு செய்ய எங்கள் முயற்சியை வழிநடத்துகிறது. காசோலை, உங்கள் காசோலைக் கடந்த 6 மாதங்களில் வரும் ஈடுபடுத்துதல் இல்லாதவையும் படிமங்களை மட்டும் கடப்பாக உங்களுக்கு பயன்படுத்துவதில் முதல் படிக்கு உங்களை அலுவலகங்களுக்கு வசதியாக்க வேண்டும்'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_wo_input=\"\"\"சரியான பதிலுடன் வேலையை வெற்றிகரமாக முடிக்க, தேவையான தகவலை உள்ளிடவும்.\n",
    "\n",
    "### Instruction:\n",
    "இ-காமர்ஸ் இணையதளத்தை உருவாக்குவதற்கான செலவை மதிப்பிடவும்.\n",
    "\n",
    "### Response:\"\"\"\n",
    "generate_response(prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485e3a8-0596-4c9c-a8b9-c12004f9ea55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
